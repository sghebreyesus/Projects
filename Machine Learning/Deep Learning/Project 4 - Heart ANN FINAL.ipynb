{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "10cf8680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samuel Ghebreyesus\n",
    "# 12-2-2022\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# function to normalize the elements in the heart dataset\n",
    "def normalize(datafile):\n",
    "        df = pd.read_csv(datafile)\n",
    "        scaledAge = df['Age'].to_numpy() / 100.0\n",
    "        gender = df['Sex'].to_numpy() == 'F'\n",
    "        gender = gender.astype(int)\n",
    "        cpt_ASY = df['ChestPainType'].to_numpy() == 'ASY'\n",
    "        cpt_ASY = cpt_ASY.astype(int)\n",
    "        cpt_NAP = df['ChestPainType'].to_numpy() == 'NAP'\n",
    "        cpt_NAP = cpt_NAP.astype(int)\n",
    "        cpt_ATA = df['ChestPainType'].to_numpy() == 'ATA'\n",
    "        cpt_ATA = cpt_ATA.astype(int)\n",
    "        cpt_TA = df['ChestPainType'].to_numpy() == 'TA'\n",
    "        cpt_TA = cpt_TA.astype(int)\n",
    "        restingBP = df['RestingBP'].to_numpy()\n",
    "        restingBP = (restingBP - 50.0) / (200 - 50)\n",
    "        cholesterol = df['Cholesterol'].to_numpy()\n",
    "        cholesterol = cholesterol / 400.0\n",
    "        fasting = df['FastingBS'].to_numpy().astype(int)\n",
    "        recg_normal = df['RestingECG'].to_numpy() == 'Normal'\n",
    "        recg_normal = recg_normal.astype(int)\n",
    "        recg_st = df['RestingECG'].to_numpy() == 'ST'\n",
    "        recg_st = recg_st.astype(int)\n",
    "        recg_lvh = df['RestingECG'].to_numpy() == 'LVH'\n",
    "        recg_lvh = recg_lvh.astype(int)\n",
    "        maxHR = (df['MaxHR'].to_numpy() - 50) / 200.0\n",
    "        exAngina = df['ExerciseAngina'].to_numpy() == 'Y'\n",
    "        exAngina = exAngina.astype(int)\n",
    "        oldpeak = (df['Oldpeak'].to_numpy() + 0.1) / 4.0\n",
    "        stslope_flat = df['ST_Slope'].to_numpy() == 'Flat'\n",
    "        stslope_flat = stslope_flat.astype(int)\n",
    "        stslope_up = df['ST_Slope'].to_numpy() == 'Up'\n",
    "        stslope_up = stslope_up.astype(int)\n",
    "        stslope_down = df['ST_Slope'].to_numpy() == 'Down'\n",
    "        stslope_down = stslope_down.astype(int)\n",
    "        labels = df['HeartDisease'].to_numpy().astype(int)\n",
    "        \n",
    "        data = np.vstack((scaledAge, \n",
    "                              gender,\n",
    "                              cpt_ASY, cpt_NAP, cpt_ATA, cpt_TA,\n",
    "                              restingBP,\n",
    "                              cholesterol,\n",
    "                              fasting,\n",
    "                              recg_normal, recg_st, recg_lvh,\n",
    "                              maxHR,\n",
    "                              exAngina,\n",
    "                              oldpeak,\n",
    "                              stslope_flat, stslope_up, stslope_down,\n",
    "                              labels)).T\n",
    "        data = data.astype(float)\n",
    "        DF = pd.DataFrame(data)\n",
    "        return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "f8459dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call on normalize function, create X and Y train/test dataframes/arrays\n",
    "df = normalize(\"C:/Users/samgh/Downloads/heart.csv\")\n",
    "train_df = normalize(\"C:/Users/samgh/Downloads/heart_train_718.csv\")\n",
    "test_df = normalize(\"C:/Users/samgh/Downloads/heart_test_200.csv\")\n",
    "X = df.iloc[:, :-1]\n",
    "X2 = X.to_numpy()\n",
    "Y = df.iloc[:, -1]\n",
    "Y2 = Y.to_numpy()\n",
    "X_train = train_df.iloc[:, :-1]\n",
    "Y_train = train_df.iloc[:, -1]\n",
    "X_train2 = X_train.to_numpy()\n",
    "Y_train2 = Y_train.to_numpy()\n",
    "X_test = test_df.iloc[:, :-1]\n",
    "Y_test = test_df.iloc[:, -1]\n",
    "X_test2 = X_test.to_numpy()\n",
    "Y_test2 = Y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "018fa0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1\n",
      "X shape: torch.Size([64, 18])\n",
      "y shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# class represents the heart dataset \n",
    "class HeartData(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = torch.from_numpy(X.astype(np.float32))\n",
    "        self.y = torch.from_numpy(Y.astype(np.float32))\n",
    "        self.len = self.X.shape[0]\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "   \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "   \n",
    "batch_size = 64\n",
    "\n",
    "# put train and test datasets into dataloader object\n",
    "train_data = HeartData(X_train2, Y_train2)\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_data = HeartData(X_test2, Y_test2)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for batch, (X, y) in enumerate(train_dataloader):\n",
    "    print(f\"Batch: {batch+1}\")\n",
    "    print(f\"X shape: {X.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "776373b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeartNet(\n",
      "  (fc1): Linear(in_features=18, out_features=20, bias=True)\n",
      "  (fc2): Linear(in_features=20, out_features=12, bias=True)\n",
      "  (output): Linear(in_features=12, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "in_features = 18\n",
    "out_features = 20\n",
    "out_features2 = 12\n",
    "out_dim = 2\n",
    "\n",
    "# Neural Network #1: consists of two fully connected linear layers \n",
    "class HeartNet(nn.Module):\n",
    "    def __init__(self, in_features, out_features, out_features2, out_dim):\n",
    "        super(HeartNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, out_features)\n",
    "        self.fc2 = nn.Linear(out_features, out_features2)\n",
    "        self.output = nn.Linear(out_features2, out_dim)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "       \n",
    "network = HeartNet(in_features, out_features, out_features2, out_dim)\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "2c70f119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing hyperparameters\n",
    "learning_rate = 0.1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(network.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "19195f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "loss_values = []\n",
    "\n",
    "# function for training neural network, takes in the train dataloader and a network model, prints out for each epoch,\n",
    "# the associated loss value\n",
    "def train(train_dataloader, network):\n",
    "    network.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            pred = network(X)\n",
    "            loss = criterion(pred, y.type(torch.LongTensor))\n",
    "            loss_values.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch: {epoch} Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "1413cc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 0.64759361743927\n",
      "Epoch: 1 Loss: 0.7372914552688599\n",
      "Epoch: 2 Loss: 0.6012390851974487\n",
      "Epoch: 3 Loss: 0.5883570313453674\n",
      "Epoch: 4 Loss: 0.504421591758728\n",
      "Epoch: 5 Loss: 0.4765053689479828\n",
      "Epoch: 6 Loss: 0.3344568610191345\n",
      "Epoch: 7 Loss: 0.4085538685321808\n",
      "Epoch: 8 Loss: 0.16527321934700012\n",
      "Epoch: 9 Loss: 0.25336506962776184\n",
      "Epoch: 10 Loss: 0.36719927191734314\n",
      "Epoch: 11 Loss: 0.46469977498054504\n",
      "Epoch: 12 Loss: 0.2066451758146286\n",
      "Epoch: 13 Loss: 0.49870166182518005\n",
      "Epoch: 14 Loss: 0.4130649268627167\n",
      "Epoch: 15 Loss: 0.5125716924667358\n",
      "Epoch: 16 Loss: 0.44209668040275574\n",
      "Epoch: 17 Loss: 0.4369516670703888\n",
      "Epoch: 18 Loss: 0.6517018675804138\n",
      "Epoch: 19 Loss: 0.2741278111934662\n",
      "Epoch: 20 Loss: 0.27365604043006897\n",
      "Epoch: 21 Loss: 0.3798691928386688\n",
      "Epoch: 22 Loss: 0.43311867117881775\n",
      "Epoch: 23 Loss: 0.17220497131347656\n",
      "Epoch: 24 Loss: 0.2744288146495819\n",
      "Epoch: 25 Loss: 0.3885229229927063\n",
      "Epoch: 26 Loss: 0.648061215877533\n",
      "Epoch: 27 Loss: 0.1787603795528412\n",
      "Epoch: 28 Loss: 0.44443315267562866\n",
      "Epoch: 29 Loss: 0.18741025030612946\n",
      "Epoch: 30 Loss: 0.12827108800411224\n",
      "Epoch: 31 Loss: 0.1229332759976387\n",
      "Epoch: 32 Loss: 0.32948312163352966\n",
      "Epoch: 33 Loss: 0.15305158495903015\n",
      "Epoch: 34 Loss: 0.4068308174610138\n",
      "Epoch: 35 Loss: 0.1604553461074829\n",
      "Epoch: 36 Loss: 0.17521235346794128\n",
      "Epoch: 37 Loss: 0.32070237398147583\n",
      "Epoch: 38 Loss: 0.3488122522830963\n",
      "Epoch: 39 Loss: 0.260960191488266\n",
      "Epoch: 40 Loss: 0.3323644697666168\n",
      "Epoch: 41 Loss: 0.1433853954076767\n",
      "Epoch: 42 Loss: 0.4958168566226959\n",
      "Epoch: 43 Loss: 0.3110290467739105\n",
      "Epoch: 44 Loss: 0.15566383302211761\n",
      "Epoch: 45 Loss: 0.3261195123195648\n",
      "Epoch: 46 Loss: 0.4557286202907562\n",
      "Epoch: 47 Loss: 0.25032201409339905\n",
      "Epoch: 48 Loss: 0.3909182548522949\n",
      "Epoch: 49 Loss: 0.2954888641834259\n",
      "Epoch: 50 Loss: 0.21834710240364075\n",
      "Epoch: 51 Loss: 0.14257009327411652\n",
      "Epoch: 52 Loss: 0.17219342291355133\n",
      "Epoch: 53 Loss: 0.2811126708984375\n",
      "Epoch: 54 Loss: 0.324819415807724\n",
      "Epoch: 55 Loss: 0.3964415192604065\n",
      "Epoch: 56 Loss: 0.527283787727356\n",
      "Epoch: 57 Loss: 0.15872399508953094\n",
      "Epoch: 58 Loss: 0.4252227246761322\n",
      "Epoch: 59 Loss: 0.5381390452384949\n",
      "Epoch: 60 Loss: 0.4876287877559662\n",
      "Epoch: 61 Loss: 0.2890739142894745\n",
      "Epoch: 62 Loss: 0.2560376822948456\n",
      "Epoch: 63 Loss: 0.36149051785469055\n",
      "Epoch: 64 Loss: 0.11111260205507278\n",
      "Epoch: 65 Loss: 0.3789350688457489\n",
      "Epoch: 66 Loss: 0.4550294578075409\n",
      "Epoch: 67 Loss: 0.16489198803901672\n",
      "Epoch: 68 Loss: 0.07846558094024658\n",
      "Epoch: 69 Loss: 0.3835242688655853\n",
      "Epoch: 70 Loss: 0.1954999417066574\n",
      "Epoch: 71 Loss: 0.21882474422454834\n",
      "Epoch: 72 Loss: 0.35972002148628235\n",
      "Epoch: 73 Loss: 0.46234074234962463\n",
      "Epoch: 74 Loss: 0.2975994646549225\n",
      "Epoch: 75 Loss: 0.12407305091619492\n",
      "Epoch: 76 Loss: 0.30338987708091736\n",
      "Epoch: 77 Loss: 0.4750169813632965\n",
      "Epoch: 78 Loss: 0.04818902164697647\n",
      "Epoch: 79 Loss: 0.6149622201919556\n",
      "Epoch: 80 Loss: 0.18051908910274506\n",
      "Epoch: 81 Loss: 0.42495831847190857\n",
      "Epoch: 82 Loss: 0.41965556144714355\n",
      "Epoch: 83 Loss: 0.2872339189052582\n",
      "Epoch: 84 Loss: 0.3184412121772766\n",
      "Epoch: 85 Loss: 0.13030852377414703\n",
      "Epoch: 86 Loss: 0.3847062885761261\n",
      "Epoch: 87 Loss: 0.11089479178190231\n",
      "Epoch: 88 Loss: 0.4913797676563263\n",
      "Epoch: 89 Loss: 0.21608875691890717\n",
      "Epoch: 90 Loss: 0.32048216462135315\n",
      "Epoch: 91 Loss: 0.10855960845947266\n",
      "Epoch: 92 Loss: 0.1049947664141655\n",
      "Epoch: 93 Loss: 0.23589058220386505\n",
      "Epoch: 94 Loss: 0.577541172504425\n",
      "Epoch: 95 Loss: 0.14869119226932526\n",
      "Epoch: 96 Loss: 0.2489994913339615\n",
      "Epoch: 97 Loss: 0.38720080256462097\n",
      "Epoch: 98 Loss: 0.22769291698932648\n",
      "Epoch: 99 Loss: 0.08712731301784515\n"
     ]
    }
   ],
   "source": [
    "# call train function\n",
    "import torch.nn.functional as F\n",
    "train(train_dataloader, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "49148cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function, takes in the test dataloader and a network model, prints out for the test set the average loss \n",
    "# and accuracy \n",
    "def test(test_dataloader, network):\n",
    "    loss_values = []\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        network.eval()\n",
    "        for X, y in test_dataloader:\n",
    "            y_pred = network(X)\n",
    "            test_loss += criterion(y_pred, y.type(torch.LongTensor))\n",
    "            pred = y_pred.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(y.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_dataloader.dataset)\n",
    "    loss_values.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_dataloader.dataset),\n",
    "        100. * correct / len(test_dataloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "34dab0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0071, Accuracy: 168/200 (84%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# call test and print out results\n",
    "test(test_dataloader, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "bade42de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network #2: consists of 2 convolution layers and one linear layer \n",
    "class HeartNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HeartNet2, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(64, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv1d(10, 5, kernel_size=5)\n",
    "        nn.Flatten()\n",
    "        self.fc1 = nn.Linear(10, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "a39bf5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeartNet2(\n",
       "  (conv1): Conv1d(64, 10, kernel_size=(5,), stride=(1,))\n",
       "  (conv2): Conv1d(10, 5, kernel_size=(5,), stride=(1,))\n",
       "  (fc1): Linear(in_features=10, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out setup of second neural network\n",
    "network2 = HeartNet2()\n",
    "network2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "ee73cdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 0.23471570014953613\n",
      "Epoch: 1 Loss: 0.19875384867191315\n",
      "Epoch: 2 Loss: 0.11649491637945175\n",
      "Epoch: 3 Loss: 0.26884010434150696\n",
      "Epoch: 4 Loss: 0.29933813214302063\n",
      "Epoch: 5 Loss: 0.22075171768665314\n",
      "Epoch: 6 Loss: 0.14443445205688477\n",
      "Epoch: 7 Loss: 0.2569844424724579\n",
      "Epoch: 8 Loss: 0.3796629309654236\n",
      "Epoch: 9 Loss: 0.3612794578075409\n",
      "Epoch: 10 Loss: 0.43122047185897827\n",
      "Epoch: 11 Loss: 0.18672263622283936\n",
      "Epoch: 12 Loss: 0.14409467577934265\n",
      "Epoch: 13 Loss: 0.14019931852817535\n",
      "Epoch: 14 Loss: 0.530377209186554\n",
      "Epoch: 15 Loss: 0.4085719883441925\n",
      "Epoch: 16 Loss: 0.2580457031726837\n",
      "Epoch: 17 Loss: 0.14605438709259033\n",
      "Epoch: 18 Loss: 0.20976577699184418\n",
      "Epoch: 19 Loss: 0.25388258695602417\n",
      "Epoch: 20 Loss: 0.6081656813621521\n",
      "Epoch: 21 Loss: 0.3749033510684967\n",
      "Epoch: 22 Loss: 0.13420896232128143\n",
      "Epoch: 23 Loss: 0.2194700390100479\n",
      "Epoch: 24 Loss: 0.126507967710495\n",
      "Epoch: 25 Loss: 0.05837346240878105\n",
      "Epoch: 26 Loss: 0.0848638191819191\n",
      "Epoch: 27 Loss: 0.3538387715816498\n",
      "Epoch: 28 Loss: 0.13460183143615723\n",
      "Epoch: 29 Loss: 0.13930971920490265\n",
      "Epoch: 30 Loss: 0.41220489144325256\n",
      "Epoch: 31 Loss: 0.2171497493982315\n",
      "Epoch: 32 Loss: 0.39030060172080994\n",
      "Epoch: 33 Loss: 0.1745556741952896\n",
      "Epoch: 34 Loss: 0.3414480984210968\n",
      "Epoch: 35 Loss: 0.14636237919330597\n",
      "Epoch: 36 Loss: 0.28630003333091736\n",
      "Epoch: 37 Loss: 0.15652251243591309\n",
      "Epoch: 38 Loss: 0.23281006515026093\n",
      "Epoch: 39 Loss: 0.6003455519676208\n",
      "Epoch: 40 Loss: 0.05728055164217949\n",
      "Epoch: 41 Loss: 0.3637862801551819\n",
      "Epoch: 42 Loss: 0.260696679353714\n",
      "Epoch: 43 Loss: 0.17755722999572754\n",
      "Epoch: 44 Loss: 0.2454613447189331\n",
      "Epoch: 45 Loss: 0.14025475084781647\n",
      "Epoch: 46 Loss: 0.47817546129226685\n",
      "Epoch: 47 Loss: 0.17322251200675964\n",
      "Epoch: 48 Loss: 0.4943598210811615\n",
      "Epoch: 49 Loss: 0.3954637944698334\n",
      "Epoch: 50 Loss: 0.1949489414691925\n",
      "Epoch: 51 Loss: 0.15750539302825928\n",
      "Epoch: 52 Loss: 0.23846204578876495\n",
      "Epoch: 53 Loss: 0.23015086352825165\n",
      "Epoch: 54 Loss: 0.1887524425983429\n",
      "Epoch: 55 Loss: 0.39629244804382324\n",
      "Epoch: 56 Loss: 0.1266978234052658\n",
      "Epoch: 57 Loss: 0.2612943947315216\n",
      "Epoch: 58 Loss: 0.2905726730823517\n",
      "Epoch: 59 Loss: 0.3263077437877655\n",
      "Epoch: 60 Loss: 0.39301374554634094\n",
      "Epoch: 61 Loss: 0.19737346470355988\n",
      "Epoch: 62 Loss: 0.11963323503732681\n",
      "Epoch: 63 Loss: 0.08990155905485153\n",
      "Epoch: 64 Loss: 0.7395762205123901\n",
      "Epoch: 65 Loss: 0.20029141008853912\n",
      "Epoch: 66 Loss: 0.15525087714195251\n",
      "Epoch: 67 Loss: 0.3879412114620209\n",
      "Epoch: 68 Loss: 0.14022667706012726\n",
      "Epoch: 69 Loss: 0.3346678912639618\n",
      "Epoch: 70 Loss: 0.26452213525772095\n",
      "Epoch: 71 Loss: 0.4221297800540924\n",
      "Epoch: 72 Loss: 0.09581143409013748\n",
      "Epoch: 73 Loss: 0.5273593068122864\n",
      "Epoch: 74 Loss: 0.2877937853336334\n",
      "Epoch: 75 Loss: 0.32847216725349426\n",
      "Epoch: 76 Loss: 0.4541831612586975\n",
      "Epoch: 77 Loss: 0.3648814857006073\n",
      "Epoch: 78 Loss: 0.3321891129016876\n",
      "Epoch: 79 Loss: 0.37346506118774414\n",
      "Epoch: 80 Loss: 0.18283139169216156\n",
      "Epoch: 81 Loss: 0.2344048023223877\n",
      "Epoch: 82 Loss: 0.0788525938987732\n",
      "Epoch: 83 Loss: 0.6406184434890747\n",
      "Epoch: 84 Loss: 0.44367724657058716\n",
      "Epoch: 85 Loss: 0.0910675898194313\n",
      "Epoch: 86 Loss: 0.13238804042339325\n",
      "Epoch: 87 Loss: 0.4407094419002533\n",
      "Epoch: 88 Loss: 0.5045831799507141\n",
      "Epoch: 89 Loss: 0.49660807847976685\n",
      "Epoch: 90 Loss: 0.12582111358642578\n",
      "Epoch: 91 Loss: 0.06850554794073105\n",
      "Epoch: 92 Loss: 0.15988542139530182\n",
      "Epoch: 93 Loss: 0.3288304805755615\n",
      "Epoch: 94 Loss: 0.21617531776428223\n",
      "Epoch: 95 Loss: 0.3415634334087372\n",
      "Epoch: 96 Loss: 0.14708180725574493\n",
      "Epoch: 97 Loss: 0.3482586443424225\n",
      "Epoch: 98 Loss: 0.44847530126571655\n",
      "Epoch: 99 Loss: 0.23331956565380096\n"
     ]
    }
   ],
   "source": [
    "# call train function and print out results \n",
    "train(train_dataloader, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "495b3c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0070, Accuracy: 162/200 (81%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# call test function and pick out results \n",
    "test(test_dataloader, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "fa543a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extension: tried another architecture where I added a dropout layer with dropout rate of 0.25 after the first convolution\n",
    "# layer\n",
    "class HeartNet3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HeartNet3, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(64, 10, kernel_size=5)\n",
    "        self.dropout1 = nn.Dropout1d(0.25)\n",
    "        self.conv2 = nn.Conv1d(10, 5, kernel_size=5)\n",
    "        nn.Flatten()\n",
    "        self.fc1 = nn.Linear(10, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "4de54594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeartNet3(\n",
       "  (conv1): Conv1d(64, 10, kernel_size=(5,), stride=(1,))\n",
       "  (dropout1): Dropout1d(p=0.25, inplace=False)\n",
       "  (conv2): Conv1d(10, 5, kernel_size=(5,), stride=(1,))\n",
       "  (fc1): Linear(in_features=10, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out contents of new architecture\n",
    "network3 = HeartNet3()\n",
    "network3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "f02a0bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 0.7578279376029968\n",
      "Epoch: 1 Loss: 0.8208339810371399\n",
      "Epoch: 2 Loss: 0.8529514670372009\n",
      "Epoch: 3 Loss: 0.7466496825218201\n",
      "Epoch: 4 Loss: 0.6920698285102844\n",
      "Epoch: 5 Loss: 0.6596370339393616\n",
      "Epoch: 6 Loss: 0.7509660720825195\n",
      "Epoch: 7 Loss: 0.7198501825332642\n",
      "Epoch: 8 Loss: 0.7869028449058533\n",
      "Epoch: 9 Loss: 0.7553368210792542\n",
      "Epoch: 10 Loss: 0.7140529751777649\n",
      "Epoch: 11 Loss: 0.7238460183143616\n",
      "Epoch: 12 Loss: 0.625843346118927\n",
      "Epoch: 13 Loss: 0.7237834334373474\n",
      "Epoch: 14 Loss: 0.754167377948761\n",
      "Epoch: 15 Loss: 0.6825264096260071\n",
      "Epoch: 16 Loss: 0.756429135799408\n",
      "Epoch: 17 Loss: 0.6198042631149292\n",
      "Epoch: 18 Loss: 0.6661861538887024\n",
      "Epoch: 19 Loss: 0.6597274541854858\n",
      "Epoch: 20 Loss: 0.6903911232948303\n",
      "Epoch: 21 Loss: 0.7586681246757507\n",
      "Epoch: 22 Loss: 0.6649648547172546\n",
      "Epoch: 23 Loss: 0.7184661626815796\n",
      "Epoch: 24 Loss: 0.7565951347351074\n",
      "Epoch: 25 Loss: 0.6587368845939636\n",
      "Epoch: 26 Loss: 0.6254586577415466\n",
      "Epoch: 27 Loss: 0.7210241556167603\n",
      "Epoch: 28 Loss: 0.789739727973938\n",
      "Epoch: 29 Loss: 0.8186284899711609\n",
      "Epoch: 30 Loss: 0.6539905667304993\n",
      "Epoch: 31 Loss: 0.7585055232048035\n",
      "Epoch: 32 Loss: 0.623491108417511\n",
      "Epoch: 33 Loss: 0.7249113321304321\n",
      "Epoch: 34 Loss: 0.6256434321403503\n",
      "Epoch: 35 Loss: 0.7172511219978333\n",
      "Epoch: 36 Loss: 0.7265034914016724\n",
      "Epoch: 37 Loss: 0.6905118823051453\n",
      "Epoch: 38 Loss: 0.6919966340065002\n",
      "Epoch: 39 Loss: 0.7506454586982727\n",
      "Epoch: 40 Loss: 0.7544127106666565\n",
      "Epoch: 41 Loss: 0.6576641798019409\n",
      "Epoch: 42 Loss: 0.6923707127571106\n",
      "Epoch: 43 Loss: 0.6544880270957947\n",
      "Epoch: 44 Loss: 0.6664667129516602\n",
      "Epoch: 45 Loss: 0.78013676404953\n",
      "Epoch: 46 Loss: 0.715837836265564\n",
      "Epoch: 47 Loss: 0.6535815596580505\n",
      "Epoch: 48 Loss: 0.6649743318557739\n",
      "Epoch: 49 Loss: 0.7924343943595886\n",
      "Epoch: 50 Loss: 0.7627937197685242\n",
      "Epoch: 51 Loss: 0.8173872232437134\n",
      "Epoch: 52 Loss: 0.6920074224472046\n",
      "Epoch: 53 Loss: 0.8616615533828735\n",
      "Epoch: 54 Loss: 0.6288391351699829\n",
      "Epoch: 55 Loss: 0.6865310668945312\n",
      "Epoch: 56 Loss: 0.6596993803977966\n",
      "Epoch: 57 Loss: 0.7984219789505005\n",
      "Epoch: 58 Loss: 0.6876763105392456\n",
      "Epoch: 59 Loss: 0.5929058790206909\n",
      "Epoch: 60 Loss: 0.6890286207199097\n",
      "Epoch: 61 Loss: 0.6864737868309021\n",
      "Epoch: 62 Loss: 0.6817129254341125\n",
      "Epoch: 63 Loss: 0.7134250998497009\n",
      "Epoch: 64 Loss: 0.596222996711731\n",
      "Epoch: 65 Loss: 0.7149465680122375\n",
      "Epoch: 66 Loss: 0.7593156099319458\n",
      "Epoch: 67 Loss: 0.635336697101593\n",
      "Epoch: 68 Loss: 0.7532490491867065\n",
      "Epoch: 69 Loss: 0.6581047773361206\n",
      "Epoch: 70 Loss: 0.6555981040000916\n",
      "Epoch: 71 Loss: 0.5967059135437012\n",
      "Epoch: 72 Loss: 0.6337370276451111\n",
      "Epoch: 73 Loss: 0.6291755437850952\n",
      "Epoch: 74 Loss: 0.7254804968833923\n",
      "Epoch: 75 Loss: 0.6857971549034119\n",
      "Epoch: 76 Loss: 0.6981831192970276\n",
      "Epoch: 77 Loss: 0.6873689889907837\n",
      "Epoch: 78 Loss: 0.6956743597984314\n",
      "Epoch: 79 Loss: 0.6905427575111389\n",
      "Epoch: 80 Loss: 0.6871824264526367\n",
      "Epoch: 81 Loss: 0.5888734459877014\n",
      "Epoch: 82 Loss: 0.6266718506813049\n",
      "Epoch: 83 Loss: 0.6906886100769043\n",
      "Epoch: 84 Loss: 0.8495613932609558\n",
      "Epoch: 85 Loss: 0.655434787273407\n",
      "Epoch: 86 Loss: 0.6538408994674683\n",
      "Epoch: 87 Loss: 0.6614962816238403\n",
      "Epoch: 88 Loss: 0.6592723727226257\n",
      "Epoch: 89 Loss: 0.6924599409103394\n",
      "Epoch: 90 Loss: 0.7250432968139648\n",
      "Epoch: 91 Loss: 0.654060959815979\n",
      "Epoch: 92 Loss: 0.7624605894088745\n",
      "Epoch: 93 Loss: 0.6554893255233765\n",
      "Epoch: 94 Loss: 0.724987804889679\n",
      "Epoch: 95 Loss: 0.7590306997299194\n",
      "Epoch: 96 Loss: 0.7175139784812927\n",
      "Epoch: 97 Loss: 0.6920586228370667\n",
      "Epoch: 98 Loss: 0.727385401725769\n",
      "Epoch: 99 Loss: 0.6932501792907715\n"
     ]
    }
   ],
   "source": [
    "# call train, print out loss results for each of 100 epochs\n",
    "train(train_dataloader, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "1d001db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0137, Accuracy: 105/200 (52%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get avg loss/accuracy for test set\n",
    "test(test_dataloader, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "4675a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extension: tried another architecture where I added a max pool layer of size 2 to each convolution layer\n",
    "class HeartNet4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HeartNet4, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(64, 10, kernel_size=5)\n",
    "        self.dropout1 = nn.Dropout1d(0.25)\n",
    "        self.conv2 = nn.Conv1d(10, 5, kernel_size=5)\n",
    "        nn.Flatten()\n",
    "        self.fc1 = nn.Linear(10, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool1d(self.conv1(x), 2))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(F.max_pool1d(self.conv2(x), 2))\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "c3cfacac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeartNet4(\n",
       "  (conv1): Conv1d(64, 10, kernel_size=(5,), stride=(1,))\n",
       "  (dropout1): Dropout1d(p=0.25, inplace=False)\n",
       "  (conv2): Conv1d(10, 5, kernel_size=(5,), stride=(1,))\n",
       "  (fc1): Linear(in_features=10, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out contents of new architecture\n",
    "network4 = HeartNet4()\n",
    "network4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "e72f9efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 0.7458941340446472\n",
      "Epoch: 1 Loss: 0.5929374694824219\n",
      "Epoch: 2 Loss: 0.6944848299026489\n",
      "Epoch: 3 Loss: 0.7281133532524109\n",
      "Epoch: 4 Loss: 0.7760716676712036\n",
      "Epoch: 5 Loss: 0.6994405388832092\n",
      "Epoch: 6 Loss: 0.6221628189086914\n",
      "Epoch: 7 Loss: 0.8135789036750793\n",
      "Epoch: 8 Loss: 0.5620203614234924\n",
      "Epoch: 9 Loss: 0.6910406351089478\n",
      "Epoch: 10 Loss: 0.6273007988929749\n",
      "Epoch: 11 Loss: 0.7237446904182434\n",
      "Epoch: 12 Loss: 0.6870070099830627\n",
      "Epoch: 13 Loss: 0.7899597883224487\n",
      "Epoch: 14 Loss: 0.6214264035224915\n",
      "Epoch: 15 Loss: 0.7987815141677856\n",
      "Epoch: 16 Loss: 0.6535539031028748\n",
      "Epoch: 17 Loss: 0.6878836750984192\n",
      "Epoch: 18 Loss: 0.689551830291748\n",
      "Epoch: 19 Loss: 0.6644907593727112\n",
      "Epoch: 20 Loss: 0.5924659967422485\n",
      "Epoch: 21 Loss: 0.6006001234054565\n",
      "Epoch: 22 Loss: 0.5976199507713318\n",
      "Epoch: 23 Loss: 0.6970958709716797\n",
      "Epoch: 24 Loss: 0.7213200926780701\n",
      "Epoch: 25 Loss: 0.6544215083122253\n",
      "Epoch: 26 Loss: 0.693144679069519\n",
      "Epoch: 27 Loss: 0.7184223532676697\n",
      "Epoch: 28 Loss: 0.6908354759216309\n",
      "Epoch: 29 Loss: 0.7607200741767883\n",
      "Epoch: 30 Loss: 0.7169150710105896\n",
      "Epoch: 31 Loss: 0.6943092346191406\n",
      "Epoch: 32 Loss: 0.7916311621665955\n",
      "Epoch: 33 Loss: 0.7201715707778931\n",
      "Epoch: 34 Loss: 0.7563456296920776\n",
      "Epoch: 35 Loss: 0.5346766114234924\n",
      "Epoch: 36 Loss: 0.6648313403129578\n",
      "Epoch: 37 Loss: 0.7851547002792358\n",
      "Epoch: 38 Loss: 0.6614078879356384\n",
      "Epoch: 39 Loss: 0.7272143959999084\n",
      "Epoch: 40 Loss: 0.6591533422470093\n",
      "Epoch: 41 Loss: 0.6315540075302124\n",
      "Epoch: 42 Loss: 0.5967145562171936\n",
      "Epoch: 43 Loss: 0.6650153994560242\n",
      "Epoch: 44 Loss: 0.6965251564979553\n",
      "Epoch: 45 Loss: 0.6922508478164673\n",
      "Epoch: 46 Loss: 0.7156773805618286\n",
      "Epoch: 47 Loss: 0.8228675723075867\n",
      "Epoch: 48 Loss: 0.691839337348938\n",
      "Epoch: 49 Loss: 0.5522211194038391\n",
      "Epoch: 50 Loss: 0.7639369964599609\n",
      "Epoch: 51 Loss: 0.6543232202529907\n",
      "Epoch: 52 Loss: 0.6534495949745178\n",
      "Epoch: 53 Loss: 0.7596483826637268\n",
      "Epoch: 54 Loss: 0.6934728026390076\n",
      "Epoch: 55 Loss: 0.5904337167739868\n",
      "Epoch: 56 Loss: 0.6630876660346985\n",
      "Epoch: 57 Loss: 0.6036086678504944\n",
      "Epoch: 58 Loss: 0.6981407403945923\n",
      "Epoch: 59 Loss: 0.6880643963813782\n",
      "Epoch: 60 Loss: 0.7926101088523865\n",
      "Epoch: 61 Loss: 0.6882857084274292\n",
      "Epoch: 62 Loss: 0.7250747084617615\n",
      "Epoch: 63 Loss: 0.8166576623916626\n",
      "Epoch: 64 Loss: 0.8183802366256714\n",
      "Epoch: 65 Loss: 0.6894747018814087\n",
      "Epoch: 66 Loss: 0.6609759330749512\n",
      "Epoch: 67 Loss: 0.7265869975090027\n",
      "Epoch: 68 Loss: 0.8253506422042847\n",
      "Epoch: 69 Loss: 0.7262315154075623\n",
      "Epoch: 70 Loss: 0.6606937646865845\n",
      "Epoch: 71 Loss: 0.7264236807823181\n",
      "Epoch: 72 Loss: 0.5626740455627441\n",
      "Epoch: 73 Loss: 0.6964918375015259\n",
      "Epoch: 74 Loss: 0.7172273397445679\n",
      "Epoch: 75 Loss: 0.7126394510269165\n",
      "Epoch: 76 Loss: 0.69370037317276\n",
      "Epoch: 77 Loss: 0.6868639588356018\n",
      "Epoch: 78 Loss: 0.6547656059265137\n",
      "Epoch: 79 Loss: 0.7938662767410278\n",
      "Epoch: 80 Loss: 0.7601333260536194\n",
      "Epoch: 81 Loss: 0.7246391177177429\n",
      "Epoch: 82 Loss: 0.6200920343399048\n",
      "Epoch: 83 Loss: 0.5956031084060669\n",
      "Epoch: 84 Loss: 0.6906502842903137\n",
      "Epoch: 85 Loss: 0.6302088499069214\n",
      "Epoch: 86 Loss: 0.7831821441650391\n",
      "Epoch: 87 Loss: 0.5868455171585083\n",
      "Epoch: 88 Loss: 0.6274061799049377\n",
      "Epoch: 89 Loss: 0.6853770017623901\n",
      "Epoch: 90 Loss: 0.756712019443512\n",
      "Epoch: 91 Loss: 0.6977269053459167\n",
      "Epoch: 92 Loss: 0.6270559430122375\n",
      "Epoch: 93 Loss: 0.6532123684883118\n",
      "Epoch: 94 Loss: 0.6571215391159058\n",
      "Epoch: 95 Loss: 0.6895411610603333\n",
      "Epoch: 96 Loss: 0.6244612336158752\n",
      "Epoch: 97 Loss: 0.6625123023986816\n",
      "Epoch: 98 Loss: 0.6880074739456177\n",
      "Epoch: 99 Loss: 0.7244938611984253\n"
     ]
    }
   ],
   "source": [
    "# print out loss for each epoch\n",
    "train(train_dataloader, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "0784a808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0145, Accuracy: 105/200 (52%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print out avg loss/accuracy for dataset\n",
    "test(test_dataloader, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d928d47e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
